{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6dcfb5f-8260-475d-9ec4-6480521a82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#students train models of lungs dataset\n",
    "#study NLP basics\n",
    "#NLP concepts (code with examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f077325f-9ebb-4961-aad5-11ed33d43020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2a324a-44c7-4051-a467-dc31f1486779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HARMAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HARMAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HARMAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HARMAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization/stemming\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "#tokenization\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de392df0-3c93-46a4-b42e-a2899a0c9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338f4a1d-090a-40bf-9904-5afe6e7e079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"My name is Ali\"\n",
    "words=word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749d17f2-691f-4e51-9cff-a7e38e9dce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', ',', 'is', '!', 'Ali']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"My name, is! Ali\"\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81032fe-f8a5-4dc8-8ba5-b5d03885c4ea",
   "metadata": {},
   "source": [
    "## sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e78d82f2-a26e-4206-b95a-d0a9e6e3d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2= \"Ali is Muslim. Ali read a book\"\n",
    "tokens=sent_tokenize(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d92968a-5c5c-479a-81a9-c2589424dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ali is Muslim.', 'Ali read a book']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac5b656b-0ea9-4231-95a7-3cbf98db9621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello!', 'Ali is Muslim.', 'Ali read a book']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2= \"Hello! Ali is Muslim. Ali read a book\"\n",
    "sent_tokenize(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45006c2-be4c-4789-a957-175284b3e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a book.', 'i like it.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"this is a book. i like it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46a5b4-41d6-4917-915d-0c1bdf93db09",
   "metadata": {},
   "source": [
    "## character tokoenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d02a66f3-5588-4d39-8e66-ffc44da54663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " '!',\n",
       " ' ',\n",
       " 'A',\n",
       " 'l',\n",
       " 'i',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'M',\n",
       " 'u',\n",
       " 's',\n",
       " 'l',\n",
       " 'i',\n",
       " 'm',\n",
       " '.',\n",
       " ' ',\n",
       " 'A',\n",
       " 'l',\n",
       " 'i',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66b56cf5-3c1c-4d29-b451-a9ec72675c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello!', 'Ali', 'is', 'Muslim.', 'Ali', 'read', 'a', 'book']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization\n",
    "s2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3648cfc6-2bb2-4d4f-aa44-7dfb31845961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1323d746-e014-486b-9448-ad1c9a77ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer() #create an object of PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "343e98c6-aaa0-43e8-9b1f-f6438fea2fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swim'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"swimming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04d19ba5-b44d-4003-a0c5-e439a1a580f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[\"connected\", \"connection\", \"connect\", \"connectivity\", \"connecting\"]\n",
    "stemmed=[]\n",
    "for i in list1:\n",
    "    temp=ps.stem(i)\n",
    "    stemmed.append(temp)\n",
    "\n",
    "#[ps.stem(i) for i in list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08ab62f6-15f0-4a65-9b3f-bfe56aee0c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['connect', 'connect', 'connect', 'connect', 'connect']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6a08168-00a1-4c0d-8fda-14e5e54e6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[\"swimming\", \"swimmed\", \"swim\", \"swam\"]\n",
    "stemmed=[]\n",
    "for i in list1:\n",
    "    temp=ps.stem(i)\n",
    "    stemmed.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "840d0c26-6100-43dd-a467-3b86487eee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swim', 'swim', 'swim', 'swam']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7bf418a-16fe-4afb-8e2a-09d72e18e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28b97a0e-dd82-4043-91ff-ff225e9db675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'runner', 'ran', 'run']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "words = ['running', 'runner', 'ran', 'runs']\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff8b5e26-ae2e-4124-9484-714ee1ab7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90a86f18-dea4-4441-b2a8-52984fb5c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0274d7c2-344d-4dae-b515-4f84b8dcd1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize(\"better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43874c4d-8ee7-484f-ae46-f1da545a60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=[\"changing\", \"swimming\", \"connected\", \"bowing\", \"borrowing\"]\n",
    "t=[lem.lemmatize(i) for i in list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77e11c6b-0313-4e6d-8980-635383ea73b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['changing', 'swimming', 'connected', 'bowing', 'borrowing']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "366fea36-eb15-4be7-a663-48dd4f0e0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HARMAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fee64c76-c2a2-4ba8-a79b-e9b2b1e58707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05074b16-6367-493e-bf92-fde5cc8a880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=[\"is\", \"pizza\", \"a\", \"had\", \"bottle\", \"hadn't\", \"ali\"]\n",
    "sw=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e25e6455-6838-4f6c-b6d8-c7ba4c8b08c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza\n",
      "bottle\n",
      "ali\n"
     ]
    }
   ],
   "source": [
    "for i in t2:\n",
    "    if i not in sw:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fcb93b-6aa9-4d6f-ad2c-ee874b5b3b97",
   "metadata": {},
   "source": [
    "## bag of words( countvectorization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a417505a-542b-44b8-b0e2-3eaa7ed07690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d2f7ec3-4d59-4439-984c-e0c646dfda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "sentences = [\"I love cats\", \"Cats is love  as had milk\"]\n",
    "\n",
    "# Create the vectorizer\n",
    "vectorizer = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9becc992-3605-4592-9cfc-a2fa21cc283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d433650b-3be8-4664-9dc2-bd075c571663",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3773b752-d26c-46cc-ba5c-681ed174899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c99120fd-0bf3-4f24-a219-0811ef2008ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cf390e34-4bee-4a2b-acbd-97dcf748a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['as', 'cats', 'had', 'is', 'love', 'milk'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df2ed8-61ab-4665-bc53-64a807d6b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a3f95-1b9f-4bf6-81ee-12ffa0d912d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
